{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-20 14:20:35--  https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.5/postgresql-42.2.5.jar\n",
      "Resolving repo1.maven.org (repo1.maven.org)... 199.232.196.209, 199.232.192.209\n",
      "Connecting to repo1.maven.org (repo1.maven.org)|199.232.196.209|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 825943 (807K) [application/java-archive]\n",
      "Saving to: ‘/home/jovyan/postgresql-42.2.5.jar’\n",
      "\n",
      "postgresql-42.2.5.j 100%[===================>] 806.58K  3.22MB/s    in 0.2s    \n",
      "\n",
      "2022-07-20 14:20:36 (3.22 MB/s) - ‘/home/jovyan/postgresql-42.2.5.jar’ saved [825943/825943]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget -P /home/jovyan https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.5/postgresql-42.2.5.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start spark application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application started\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--driver-class-path /home/jovyan/postgresql-42.2.5.jar --jars /home/jovyan/postgresql-42.2.5.jar pyspark-shell'\n",
    "\n",
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "        .master(\"local[1]\") \\\n",
    "        .appName(\"snapshot\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "print(\"Application started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm-up spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark application is ready for work\n"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.range(1000).sum()\n",
    "print(\"Spark application is ready for work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read some PostgreSQL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers table\n",
      "+----+----------+---------+--------------------+\n",
      "|  id|first_name|last_name|               email|\n",
      "+----+----------+---------+--------------------+\n",
      "|1001|     Sally|   Thomas|sally.thomas@acme...|\n",
      "|1002|    George|   Bailey|  gbailey@foobar.com|\n",
      "|1003|    Edward|   Walker|       ed@walker.com|\n",
      "|1004|      Anne|Kretchmar|  annek@noanswer.org|\n",
      "+----+----------+---------+--------------------+\n",
      "\n",
      "Orders table\n",
      "+-----+----------+---------+--------+----------+\n",
      "|   id|order_date|purchaser|quantity|product_id|\n",
      "+-----+----------+---------+--------+----------+\n",
      "|10001|2016-01-16|     1001|       1|       102|\n",
      "|10002|2016-01-17|     1002|       2|       105|\n",
      "|10003|2016-02-19|     1002|       2|       106|\n",
      "|10004|2016-02-21|     1003|       1|       107|\n",
      "+-----+----------+---------+--------+----------+\n",
      "\n",
      "Products table\n",
      "+---+------------------+--------------------+------+\n",
      "| id|              name|         description|weight|\n",
      "+---+------------------+--------------------+------+\n",
      "|101|           scooter|Small 2-wheel sco...|  3.14|\n",
      "|102|       car battery|     12V car battery|   8.1|\n",
      "|103|12-pack drill bits|12-pack of drill ...|   0.8|\n",
      "|104|            hammer|12oz carpenter's ...|  0.75|\n",
      "|105|            hammer|14oz carpenter's ...| 0.875|\n",
      "+---+------------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers = spark.read.format('jdbc').options(\n",
    "        url = \"jdbc:postgresql://postgres:5432/postgres?user=postgres&password=postgres&currentSchema=inventory\",\n",
    "        database='postgres',\n",
    "        dbtable='customers'\n",
    "    ).load()\n",
    "\n",
    "products = spark.read.format('jdbc').options(\n",
    "        url = \"jdbc:postgresql://postgres:5432/postgres?user=postgres&password=postgres&currentSchema=inventory\",\n",
    "        database='postgres',\n",
    "        dbtable='products'\n",
    "    ).load()\n",
    "\n",
    "orders = spark.read.format('jdbc').options(\n",
    "        url = \"jdbc:postgresql://postgres:5432/postgres?user=postgres&password=postgres&currentSchema=inventory\",\n",
    "        database='postgres',\n",
    "        dbtable='orders'\n",
    "    ).load()\n",
    "\n",
    "customers.registerTempTable(\"customers\")\n",
    "products.registerTempTable(\"products\")\n",
    "orders.registerTempTable(\"orders\")\n",
    "\n",
    "print(\"Customers table\")\n",
    "customers.show(5)\n",
    "print(\"Orders table\")\n",
    "orders.show(5)\n",
    "print(\"Products table\")\n",
    "products.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and join the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please write your query here\n",
    "query = \"select * from customers\"\n",
    "result = spark.sql(query)\n",
    "(result\n",
    " .selectExpr(\"*\", \"CURRENT_TIMESTAMP() as Load_Dttm\")\n",
    " .write\n",
    " .format(\"parquet\")\n",
    " .mode(\"overwrite\")\n",
    " .save(\"/home/jovyan/weight_report\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+--------------------+--------------------+\n",
      "|  id|first_name|last_name|               email|           Load_Dttm|\n",
      "+----+----------+---------+--------------------+--------------------+\n",
      "|1001|     Sally|   Thomas|sally.thomas@acme...|2022-07-20 14:51:...|\n",
      "|1002|    George|   Bailey|  gbailey@foobar.com|2022-07-20 14:51:...|\n",
      "|1003|    Edward|   Walker|       ed@walker.com|2022-07-20 14:51:...|\n",
      "|1004|      Anne|Kretchmar|  annek@noanswer.org|2022-07-20 14:51:...|\n",
      "+----+----------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read \\\n",
    "    .format(\"parquet\").load(\"/home/jovyan/weight_report\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
